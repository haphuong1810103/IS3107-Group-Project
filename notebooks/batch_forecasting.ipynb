{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8025f83",
   "metadata": {},
   "source": [
    "# Financial Forecasting Model\n",
    "\n",
    "## Steps\n",
    "1. Read rows from Google BigQuery\n",
    "2. Train forecasting model\n",
    "    - ARIMA\n",
    "    - LSTM\n",
    "3. Generate 30 day forecasts\n",
    "4. Backtest\n",
    "5. Insert predicted closing prices into Google BigQuery table\n",
    "6. Visualize in Looker Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4a64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is3107-project-455413\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "TABLE_ID = \"is3107-project-455413.market_data.yf_daily_json\"\n",
    "BIGQUERY_COLUMNS = [\"Ticker\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "TRAINING_TIMESTAMP = datetime.now()\n",
    "\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f886f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhdjabir/repo/IS3107-Group-Project/.venv/lib/python3.10/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(PROJECT_ID)\n",
    "query = f\"\"\"\n",
    "SELECT Ticker, Date, Open, High, Low, Close, Volume\n",
    "FROM `{TABLE_ID}`\n",
    "\"\"\"\n",
    "\n",
    "df = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c86d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker        Date        Open        High         Low       Close  \\\n",
      "0   AAPL  2023-01-03  128.782641  129.395510  122.742865  123.632523   \n",
      "1   AAPL  2023-01-04  125.431607  127.181268  123.642412  124.907700   \n",
      "2   AAPL  2023-01-05  125.668865  126.301508  123.326108  123.583115   \n",
      "3   AAPL  2023-01-06  124.561702  128.792501  123.454572  128.130203   \n",
      "4   AAPL  2023-01-09  128.970474  131.876686  128.397138  128.654144   \n",
      "\n",
      "      Volume  \n",
      "0  112117500  \n",
      "1   89113600  \n",
      "2   80962700  \n",
      "3   87754700  \n",
      "4   70790800  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57698 entries, 0 to 57697\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Ticker  57698 non-null  object \n",
      " 1   Date    57698 non-null  dbdate \n",
      " 2   Open    57698 non-null  float64\n",
      " 3   High    57698 non-null  float64\n",
      " 4   Low     57698 non-null  float64\n",
      " 5   Close   57698 non-null  float64\n",
      " 6   Volume  57698 non-null  Int64  \n",
      "dtypes: Int64(1), dbdate(1), float64(4), object(1)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())\n",
    "tickers = df[\"Ticker\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5901ef",
   "metadata": {},
   "source": [
    "### ARIMA Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5dd7d3",
   "metadata": {},
   "source": [
    "#### Model training and Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5798d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING AAPL\n",
      "AAPL - ARIMA(0, 1, 2) | RMSE: 17.45, MAE: 13.86\n",
      "PROCESSING MSFT\n",
      "MSFT - ARIMA(0, 1, 0) | RMSE: 23.86, MAE: 20.28\n",
      "PROCESSING NVDA\n",
      "NVDA - ARIMA(2, 1, 3) | RMSE: 14.64, MAE: 11.72\n",
      "PROCESSING GOOG\n",
      "GOOG - ARIMA(0, 1, 0) | RMSE: 16.25, MAE: 13.40\n",
      "PROCESSING GOOGL\n",
      "GOOGL - ARIMA(0, 1, 0) | RMSE: 16.37, MAE: 13.53\n",
      "PROCESSING AMZN\n",
      "AMZN - ARIMA(2, 1, 2) | RMSE: 30.68, MAE: 26.93\n",
      "PROCESSING META\n",
      "META - ARIMA(0, 1, 0) | RMSE: 69.99, MAE: 55.05\n",
      "PROCESSING BRK-B\n",
      "BRK-B - ARIMA(2, 1, 0) | RMSE: 41.13, MAE: 32.06\n",
      "PROCESSING BRK-A\n",
      "BRK-A - ARIMA(0, 1, 2) | RMSE: 60923.74, MAE: 47230.57\n",
      "PROCESSING AVGO\n",
      "AVGO - ARIMA(0, 1, 0) | RMSE: 40.28, MAE: 31.27\n",
      "PROCESSING TSM\n",
      "TSM - ARIMA(3, 1, 2) | RMSE: 18.32, MAE: 14.88\n",
      "PROCESSING LLY\n",
      "LLY - ARIMA(2, 1, 2) | RMSE: 53.82, MAE: 44.16\n",
      "PROCESSING TSLA\n",
      "TSLA - ARIMA(0, 1, 0) | RMSE: 110.29, MAE: 89.40\n",
      "PROCESSING WMT\n",
      "WMT - ARIMA(0, 1, 0) | RMSE: 11.57, MAE: 10.11\n",
      "PROCESSING JPM\n",
      "JPM - ARIMA(2, 1, 2) | RMSE: 29.28, MAE: 25.57\n",
      "PROCESSING V\n",
      "V - ARIMA(0, 1, 0) | RMSE: 42.27, MAE: 38.43\n",
      "PROCESSING MA\n",
      "MA - ARIMA(0, 1, 0) | RMSE: 39.84, MAE: 35.04\n",
      "PROCESSING XOM\n",
      "XOM - ARIMA(0, 1, 0) | RMSE: 6.42, MAE: 5.65\n",
      "PROCESSING NFLX\n",
      "NFLX - ARIMA(0, 1, 0) | RMSE: 177.93, MAE: 165.32\n",
      "PROCESSING COST\n",
      "COST - ARIMA(0, 1, 0) | RMSE: 103.72, MAE: 91.41\n",
      "PROCESSING AZN\n",
      "AZN - ARIMA(0, 1, 0) | RMSE: 4.66, MAE: 4.24\n",
      "PROCESSING PG\n",
      "PG - ARIMA(0, 1, 0) | RMSE: 5.99, MAE: 4.97\n",
      "PROCESSING UNH\n",
      "UNH - ARIMA(2, 1, 2) | RMSE: 52.15, MAE: 45.53\n",
      "PROCESSING JNJ\n",
      "JNJ - ARIMA(0, 1, 0) | RMSE: 8.41, MAE: 7.33\n",
      "PROCESSING ORCL\n",
      "ORCL - ARIMA(0, 1, 0) | RMSE: 17.68, MAE: 14.00\n",
      "PROCESSING HD\n",
      "HD - ARIMA(0, 1, 2) | RMSE: 23.88, MAE: 19.80\n",
      "PROCESSING KO\n",
      "KO - ARIMA(0, 1, 0) | RMSE: 4.27, MAE: 3.65\n",
      "PROCESSING ABBV\n",
      "ABBV - ARIMA(0, 1, 0) | RMSE: 21.48, MAE: 18.43\n",
      "PROCESSING SAP\n",
      "SAP - ARIMA(0, 1, 0) | RMSE: 31.58, MAE: 26.47\n",
      "PROCESSING TMUS\n",
      "TMUS - ARIMA(0, 1, 0) | RMSE: 27.85, MAE: 22.80\n",
      "PROCESSING NVO\n",
      "NVO - ARIMA(2, 1, 2) | RMSE: 27.85, MAE: 23.93\n",
      "PROCESSING BAC\n",
      "BAC - ARIMA(2, 1, 0) | RMSE: 3.98, MAE: 3.58\n",
      "PROCESSING BABA\n",
      "BABA - ARIMA(0, 1, 0) | RMSE: 22.49, MAE: 18.06\n",
      "PROCESSING PM\n",
      "PM - ARIMA(0, 1, 0) | RMSE: 16.30, MAE: 13.26\n",
      "PROCESSING ASML\n",
      "ASML - ARIMA(0, 1, 0) | RMSE: 49.01, MAE: 41.09\n",
      "PROCESSING MC.PA\n",
      "MC.PA - ARIMA(0, 1, 0) | RMSE: 64.13, MAE: 50.91\n",
      "PROCESSING RMS.PA\n",
      "RMS.PA - ARIMA(0, 1, 0) | RMSE: 406.79, MAE: 339.77\n",
      "PROCESSING CVX\n",
      "CVX - ARIMA(2, 0, 1) | RMSE: 9.53, MAE: 8.34\n",
      "PROCESSING CRM\n",
      "CRM - ARIMA(0, 1, 0) | RMSE: 39.32, MAE: 34.82\n",
      "PROCESSING TM\n",
      "TM - ARIMA(2, 1, 0) | RMSE: 11.51, MAE: 9.17\n",
      "PROCESSING PLTR\n",
      "PLTR - ARIMA(0, 1, 2) | RMSE: 42.20, MAE: 39.14\n",
      "PROCESSING RY.TO\n",
      "RY.TO - ARIMA(2, 1, 2) | RMSE: 5.79, MAE: 4.86\n",
      "PROCESSING ABT\n",
      "ABT - ARIMA(2, 1, 2) | RMSE: 13.19, MAE: 10.31\n",
      "PROCESSING MCD\n",
      "MCD - ARIMA(0, 1, 0) | RMSE: 13.25, MAE: 10.37\n",
      "PROCESSING IBM\n",
      "IBM - ARIMA(2, 1, 2) | RMSE: 41.39, MAE: 37.24\n",
      "PROCESSING NVS\n",
      "NVS - ARIMA(0, 1, 0) | RMSE: 5.96, MAE: 4.87\n",
      "PROCESSING CSCO\n",
      "CSCO - ARIMA(0, 1, 0) | RMSE: 5.89, MAE: 5.34\n",
      "PROCESSING WFC\n",
      "WFC - ARIMA(3, 1, 3) | RMSE: 9.57, MAE: 8.52\n",
      "PROCESSING LIN\n",
      "LIN - ARIMA(2, 1, 0) | RMSE: 17.66, MAE: 12.72\n",
      "PROCESSING GE\n",
      "GE - ARIMA(0, 1, 2) | RMSE: 21.11, MAE: 16.82\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>predicted_close</th>\n",
       "      <th>actual_close</th>\n",
       "      <th>type</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>model</th>\n",
       "      <th>training_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Date\n",
       "2024-11-01    225.123453\n",
       "2024-11-01    22...</td>\n",
       "      <td>Date\n",
       "2024-11-01    222.420471\n",
       "2024-11-01    22...</td>\n",
       "      <td>backtest</td>\n",
       "      <td>17.453411</td>\n",
       "      <td>13.859516</td>\n",
       "      <td>ARIMA(0, 1, 2)</td>\n",
       "      <td>2025-04-23 17:16:07.184637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Date\n",
       "2024-11-01    225.123453\n",
       "2024-11-01    22...</td>\n",
       "      <td>Date\n",
       "2024-11-01    222.420471\n",
       "2024-11-01    22...</td>\n",
       "      <td>backtest</td>\n",
       "      <td>17.453411</td>\n",
       "      <td>13.859516</td>\n",
       "      <td>ARIMA(0, 1, 2)</td>\n",
       "      <td>2025-04-23 17:16:07.184637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Date\n",
       "2024-11-04    225.123451\n",
       "2024-11-04    22...</td>\n",
       "      <td>Date\n",
       "2024-11-04    221.522446\n",
       "2024-11-04    22...</td>\n",
       "      <td>backtest</td>\n",
       "      <td>17.453411</td>\n",
       "      <td>13.859516</td>\n",
       "      <td>ARIMA(0, 1, 2)</td>\n",
       "      <td>2025-04-23 17:16:07.184637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Date\n",
       "2024-11-04    225.123451\n",
       "2024-11-04    22...</td>\n",
       "      <td>Date\n",
       "2024-11-04    221.522446\n",
       "2024-11-04    22...</td>\n",
       "      <td>backtest</td>\n",
       "      <td>17.453411</td>\n",
       "      <td>13.859516</td>\n",
       "      <td>ARIMA(0, 1, 2)</td>\n",
       "      <td>2025-04-23 17:16:07.184637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Date\n",
       "2024-11-05    225.123451\n",
       "2024-11-05    22...</td>\n",
       "      <td>Date\n",
       "2024-11-05    222.95929\n",
       "2024-11-05    222...</td>\n",
       "      <td>backtest</td>\n",
       "      <td>17.453411</td>\n",
       "      <td>13.859516</td>\n",
       "      <td>ARIMA(0, 1, 2)</td>\n",
       "      <td>2025-04-23 17:16:07.184637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker                                    predicted_close  \\\n",
       "0  2024-11-01   AAPL  Date\n",
       "2024-11-01    225.123453\n",
       "2024-11-01    22...   \n",
       "1  2024-11-01   AAPL  Date\n",
       "2024-11-01    225.123453\n",
       "2024-11-01    22...   \n",
       "2  2024-11-04   AAPL  Date\n",
       "2024-11-04    225.123451\n",
       "2024-11-04    22...   \n",
       "3  2024-11-04   AAPL  Date\n",
       "2024-11-04    225.123451\n",
       "2024-11-04    22...   \n",
       "4  2024-11-05   AAPL  Date\n",
       "2024-11-05    225.123451\n",
       "2024-11-05    22...   \n",
       "\n",
       "                                        actual_close      type       rmse  \\\n",
       "0  Date\n",
       "2024-11-01    222.420471\n",
       "2024-11-01    22...  backtest  17.453411   \n",
       "1  Date\n",
       "2024-11-01    222.420471\n",
       "2024-11-01    22...  backtest  17.453411   \n",
       "2  Date\n",
       "2024-11-04    221.522446\n",
       "2024-11-04    22...  backtest  17.453411   \n",
       "3  Date\n",
       "2024-11-04    221.522446\n",
       "2024-11-04    22...  backtest  17.453411   \n",
       "4  Date\n",
       "2024-11-05    222.95929\n",
       "2024-11-05    222...  backtest  17.453411   \n",
       "\n",
       "         mae           model         training_timestamp  \n",
       "0  13.859516  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
       "1  13.859516  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
       "2  13.859516  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
       "3  13.859516  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
       "4  13.859516  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "forecast_records = []\n",
    "best_orders_by_ticker = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"PROCESSING {ticker}\")\n",
    "    try:\n",
    "        ticker_df = df[df[\"Ticker\"] == ticker].sort_values(\"Date\")\n",
    "        ticker_df.set_index(\"Date\", inplace=True)\n",
    "        series = ticker_df[\"Close\"]\n",
    "\n",
    "        if len(series) < 20:\n",
    "            print(f\"Not enough data for {ticker}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        train_size = int(len(series) * 0.8)\n",
    "        train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "        best_aic = float(\"inf\")\n",
    "        best_order = None\n",
    "        best_model = None\n",
    "\n",
    "        for p in range(0, 4):\n",
    "            for d in range(0, 2):\n",
    "                for q in range(0, 4):\n",
    "                    try:\n",
    "                        model = ARIMA(train, order=(p, d, q))\n",
    "                        model_fit = model.fit()\n",
    "                        if model_fit.aic < best_aic:\n",
    "                            best_aic = model_fit.aic\n",
    "                            best_order = (p, d, q)\n",
    "                            best_model = model_fit\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        if best_model:\n",
    "            best_orders_by_ticker[ticker] = best_order\n",
    "            forecast = best_model.forecast(len(test))\n",
    "            forecast.index = test.index\n",
    "            rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "            mae = mean_absolute_error(test, forecast)\n",
    "            print(f\"{ticker} - ARIMA{best_order} | RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "            for date in test.index:\n",
    "                forecast_records.append({\n",
    "                    \"date\": date,\n",
    "                    \"ticker\": ticker,\n",
    "                    \"predicted_close\": forecast.loc[date],\n",
    "                    \"actual_close\": test.loc[date],\n",
    "                    \"type\": \"backtest\",\n",
    "                    \"rmse\": rmse,\n",
    "                    \"mae\": mae,\n",
    "                    \"model\": f\"ARIMA{best_order}\",\n",
    "                    \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "backtest_forecast_df = pd.DataFrame(forecast_records)\n",
    "backtest_forecast_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef22ba6",
   "metadata": {},
   "source": [
    "#### 7-Day forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317cbd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTING FUTURE FOR AAPL\n",
      "PREDICTING FUTURE FOR MSFT\n",
      "PREDICTING FUTURE FOR NVDA\n",
      "PREDICTING FUTURE FOR GOOG\n",
      "PREDICTING FUTURE FOR GOOGL\n",
      "PREDICTING FUTURE FOR AMZN\n",
      "PREDICTING FUTURE FOR META\n",
      "PREDICTING FUTURE FOR BRK-B\n",
      "PREDICTING FUTURE FOR BRK-A\n",
      "PREDICTING FUTURE FOR AVGO\n",
      "PREDICTING FUTURE FOR TSM\n",
      "PREDICTING FUTURE FOR LLY\n",
      "PREDICTING FUTURE FOR TSLA\n",
      "PREDICTING FUTURE FOR WMT\n",
      "PREDICTING FUTURE FOR JPM\n",
      "PREDICTING FUTURE FOR V\n",
      "PREDICTING FUTURE FOR MA\n",
      "PREDICTING FUTURE FOR XOM\n",
      "PREDICTING FUTURE FOR NFLX\n",
      "PREDICTING FUTURE FOR COST\n",
      "PREDICTING FUTURE FOR AZN\n",
      "PREDICTING FUTURE FOR PG\n",
      "PREDICTING FUTURE FOR UNH\n",
      "PREDICTING FUTURE FOR JNJ\n",
      "PREDICTING FUTURE FOR ORCL\n",
      "PREDICTING FUTURE FOR HD\n",
      "PREDICTING FUTURE FOR KO\n",
      "PREDICTING FUTURE FOR ABBV\n",
      "PREDICTING FUTURE FOR SAP\n",
      "PREDICTING FUTURE FOR TMUS\n",
      "PREDICTING FUTURE FOR NVO\n",
      "PREDICTING FUTURE FOR BAC\n",
      "PREDICTING FUTURE FOR BABA\n",
      "PREDICTING FUTURE FOR PM\n",
      "PREDICTING FUTURE FOR ASML\n",
      "PREDICTING FUTURE FOR MC.PA\n",
      "PREDICTING FUTURE FOR RMS.PA\n",
      "PREDICTING FUTURE FOR CVX\n",
      "PREDICTING FUTURE FOR CRM\n",
      "PREDICTING FUTURE FOR TM\n",
      "PREDICTING FUTURE FOR PLTR\n",
      "PREDICTING FUTURE FOR RY.TO\n",
      "PREDICTING FUTURE FOR ABT\n",
      "PREDICTING FUTURE FOR MCD\n",
      "PREDICTING FUTURE FOR IBM\n",
      "PREDICTING FUTURE FOR NVS\n",
      "PREDICTING FUTURE FOR CSCO\n",
      "PREDICTING FUTURE FOR WFC\n",
      "PREDICTING FUTURE FOR LIN\n",
      "PREDICTING FUTURE FOR GE\n",
      "          date ticker  predicted_close actual_close        type  rmse   mae  \\\n",
      "345 2025-04-25     GE        188.80379         None  prediction  None  None   \n",
      "346 2025-04-26     GE        188.80379         None  prediction  None  None   \n",
      "347 2025-04-27     GE        188.80379         None  prediction  None  None   \n",
      "348 2025-04-28     GE        188.80379         None  prediction  None  None   \n",
      "349 2025-04-29     GE        188.80379         None  prediction  None  None   \n",
      "\n",
      "              model         training_timestamp  \n",
      "345  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
      "346  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
      "347  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
      "348  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n",
      "349  ARIMA(0, 1, 2) 2025-04-23 17:16:07.184637  \n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "forecast_records = []\n",
    "for ticker in tickers:\n",
    "    print(f\"PREDICTING FUTURE FOR {ticker}\")\n",
    "    try:\n",
    "        if ticker not in best_orders_by_ticker:\n",
    "            print(f\"No ARIMA order found from backtest for {ticker}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        order = best_orders_by_ticker[ticker]\n",
    "        ticker_df = df[df[\"Ticker\"] == ticker].sort_values(\"Date\")\n",
    "        ticker_df.set_index(\"Date\", inplace=True)\n",
    "        series = ticker_df[\"Close\"]\n",
    "\n",
    "        model = ARIMA(series, order=order)\n",
    "        model_fit = model.fit()\n",
    "        forecast = model_fit.forecast(steps=7)\n",
    "\n",
    "        last_date = series.index[-1]\n",
    "        forecast_dates = pd.date_range(start=last_date + timedelta(days=1), periods=7, freq=\"D\")\n",
    "\n",
    "        for date, pred in zip(forecast_dates, forecast):\n",
    "            forecast_records.append({\n",
    "                \"date\": date,\n",
    "                \"ticker\": ticker,\n",
    "                \"predicted_close\": pred,\n",
    "                \"actual_close\": None,\n",
    "                \"type\": \"prediction\",\n",
    "                \"rmse\": None,\n",
    "                \"mae\": None,\n",
    "                \"model\": f\"ARIMA{order}\",\n",
    "                \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting future for {ticker}: {e}\")\n",
    "\n",
    "\n",
    "prediction_forecast_df = pd.DataFrame(forecast_records)\n",
    "print(prediction_forecast_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc6a5a",
   "metadata": {},
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c2f7b",
   "metadata": {},
   "source": [
    "#### Model training and Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85444353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"Ticker\", \"Date\"])\n",
    "\n",
    "for window in [5, 10, 20]:\n",
    "    df[f\"MA_{window}\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.rolling(window).mean())\n",
    "    df[f\"Volume_MA_{window}\"] = df.groupby(\"Ticker\")[\"Volume\"].transform(lambda x: x.rolling(window).mean())\n",
    "\n",
    "for lag in range(1, 8):\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"Ticker\")[\"Close\"].shift(lag)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    df[f\"Close_t+{i}\"] = df.groupby(\"Ticker\")[\"Close\"].shift(-i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648a694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost for AAPL\n",
      "Training XGBoost for MSFT\n",
      "Training XGBoost for NVDA\n",
      "Training XGBoost for GOOG\n",
      "Training XGBoost for GOOGL\n",
      "Training XGBoost for AMZN\n",
      "Training XGBoost for META\n",
      "Training XGBoost for BRK-B\n",
      "Training XGBoost for BRK-A\n",
      "Training XGBoost for AVGO\n",
      "Training XGBoost for TSM\n",
      "Training XGBoost for LLY\n",
      "Training XGBoost for TSLA\n",
      "Training XGBoost for WMT\n",
      "Training XGBoost for JPM\n",
      "Training XGBoost for V\n",
      "Training XGBoost for MA\n",
      "Training XGBoost for XOM\n",
      "Training XGBoost for NFLX\n",
      "Training XGBoost for COST\n",
      "Training XGBoost for AZN\n",
      "Training XGBoost for PG\n",
      "Training XGBoost for UNH\n",
      "Training XGBoost for JNJ\n",
      "Training XGBoost for ORCL\n",
      "Training XGBoost for HD\n",
      "Training XGBoost for KO\n",
      "Training XGBoost for ABBV\n",
      "Training XGBoost for SAP\n",
      "Training XGBoost for TMUS\n",
      "Training XGBoost for NVO\n",
      "Training XGBoost for BAC\n",
      "Training XGBoost for BABA\n",
      "Training XGBoost for PM\n",
      "Training XGBoost for ASML\n",
      "Training XGBoost for MC.PA\n",
      "Training XGBoost for RMS.PA\n",
      "Training XGBoost for CVX\n",
      "Training XGBoost for CRM\n",
      "Training XGBoost for TM\n",
      "Training XGBoost for PLTR\n",
      "Training XGBoost for RY.TO\n",
      "Training XGBoost for ABT\n",
      "Training XGBoost for MCD\n",
      "Training XGBoost for IBM\n",
      "Training XGBoost for NVS\n",
      "Training XGBoost for CSCO\n",
      "Training XGBoost for WFC\n",
      "Training XGBoost for LIN\n",
      "Training XGBoost for GE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "forecast_records = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Training XGBoost for {ticker}\")\n",
    "    ticker_df = df[df[\"Ticker\"] == ticker]\n",
    "\n",
    "    feature_cols = ['Open', 'High', 'Low', 'Volume',\n",
    "                    'MA_5', 'MA_10', 'MA_20',\n",
    "                    'Volume_MA_5', 'Volume_MA_10', 'Volume_MA_20'] + \\\n",
    "                   [f\"lag_{i}\" for i in range(1, 8)]\n",
    "    \n",
    "    target_cols = [f\"Close_t+{i}\" for i in range(1, 8)]\n",
    "\n",
    "    X = ticker_df[feature_cols]\n",
    "    y = ticker_df[target_cols]\n",
    "\n",
    "    # Split data for backtesting\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = MultiOutputRegressor(XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5))\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "\n",
    "    test_dates = ticker_df[\"Date\"].iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        actuals = y_test.iloc[i].values\n",
    "\n",
    "        for day in range(7):  # Predict each future day (t+1 to t+7)\n",
    "            predicted_close = y_pred[i][day]\n",
    "            \n",
    "            all_predictions.append(predicted_close)\n",
    "            all_actuals.append(actuals[day])\n",
    "\n",
    "            forecast_records.append({\n",
    "                \"date\": test_dates[i] + pd.Timedelta(days=day+1),  # t+1 to t+7\n",
    "                \"ticker\": ticker,\n",
    "                \"predicted_close\": predicted_close,\n",
    "                \"actual_close\": actuals[day],\n",
    "                \"type\": \"backtest\",\n",
    "                \"rmse\": None,\n",
    "                \"mae\": None, \n",
    "                \"model\": \"XGBoost\",\n",
    "                \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "            })\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_actuals = np.array(all_actuals)\n",
    "\n",
    "    valid_mask = ~np.isnan(all_predictions) & ~np.isnan(all_actuals)\n",
    "\n",
    "    total_rmse = np.sqrt(mean_squared_error(all_actuals[valid_mask], all_predictions[valid_mask]))\n",
    "    total_mae = mean_absolute_error(all_actuals[valid_mask], all_predictions[valid_mask])\n",
    "\n",
    "    for record in forecast_records:\n",
    "        if record[\"type\"] == \"backtest\" and record[\"ticker\"] == ticker:\n",
    "            record[\"rmse\"] = total_rmse\n",
    "            record[\"mae\"] = total_mae\n",
    "\n",
    "    X_latest = X.iloc[[-1]]\n",
    "    y_future_pred = model.predict(X_latest)[0]\n",
    "\n",
    "    last_date = ticker_df[\"Date\"].max()\n",
    "    forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=7)\n",
    "\n",
    "    for i, pred in enumerate(y_future_pred):\n",
    "        forecast_records.append({\n",
    "            \"date\": forecast_dates[i],\n",
    "            \"ticker\": ticker,\n",
    "            \"predicted_close\": pred,\n",
    "            \"actual_close\": None,\n",
    "            \"type\": \"prediction\",\n",
    "            \"rmse\": None,\n",
    "            \"mae\": None,\n",
    "            \"model\": \"XGBoost\",\n",
    "            \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "        })\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd46747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date ticker  predicted_close  actual_close        type  \\\n",
      "81258  2025-04-25 00:00:00     GE       180.417130           NaN  prediction   \n",
      "81259  2025-04-26 00:00:00     GE       183.382126           NaN  prediction   \n",
      "81260  2025-04-27 00:00:00     GE       176.614014           NaN  prediction   \n",
      "81261  2025-04-28 00:00:00     GE       176.428482           NaN  prediction   \n",
      "81262  2025-04-29 00:00:00     GE       181.173233           NaN  prediction   \n",
      "\n",
      "       rmse  mae    model         training_timestamp  \n",
      "81258   NaN  NaN  XGBoost 2025-04-23 17:16:07.184637  \n",
      "81259   NaN  NaN  XGBoost 2025-04-23 17:16:07.184637  \n",
      "81260   NaN  NaN  XGBoost 2025-04-23 17:16:07.184637  \n",
      "81261   NaN  NaN  XGBoost 2025-04-23 17:16:07.184637  \n",
      "81262   NaN  NaN  XGBoost 2025-04-23 17:16:07.184637  \n"
     ]
    }
   ],
   "source": [
    "xgboost_prediction_forecast_df = pd.DataFrame(forecast_records)\n",
    "print(xgboost_prediction_forecast_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56571fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "DESTINATION_TABLE_ID = \"is3107-project-455413.market_data.stock_forecast\"\n",
    "final_forecast_df = pd.concat([backtest_forecast_df, prediction_forecast_df, xgboost_prediction_forecast_df])\n",
    "\n",
    "final_forecast_df[\"date\"] = pd.to_datetime(final_forecast_df[\"date\"], errors='coerce')\n",
    "final_forecast_df[\"training_timestamp\"] = pd.to_datetime(final_forecast_df[\"training_timestamp\"], errors='coerce')\n",
    "\n",
    "final_forecast_df[\"ticker\"] = final_forecast_df[\"ticker\"].astype(str)\n",
    "final_forecast_df[\"type\"] = final_forecast_df[\"type\"].astype(str)\n",
    "final_forecast_df[\"model\"] = final_forecast_df[\"model\"].astype(str)\n",
    "\n",
    "final_forecast_df[\"predicted_close\"] = pd.to_numeric(final_forecast_df[\"predicted_close\"], errors='coerce')\n",
    "final_forecast_df[\"actual_close\"] = pd.to_numeric(final_forecast_df[\"actual_close\"], errors='coerce')\n",
    "\n",
    "to_gbq(\n",
    "    final_forecast_df,\n",
    "    DESTINATION_TABLE_ID,\n",
    "    project_id=PROJECT_ID,\n",
    "    if_exists='append',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
