{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8025f83",
   "metadata": {},
   "source": [
    "# Financial Forecasting Model\n",
    "\n",
    "## Steps\n",
    "1. Read rows from Google BigQuery\n",
    "2. Train forecasting model\n",
    "    - ARIMA\n",
    "    - LSTM\n",
    "3. Generate 30 day forecasts\n",
    "4. Backtest\n",
    "5. Insert predicted closing prices into Google BigQuery table\n",
    "6. Visualize in Looker Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4a64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is3107-project-455413\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\")\n",
    "TABLE_ID = \"is3107-project-455413.market_data.yf_daily_json\"\n",
    "BIGQUERY_COLUMNS = [\"Ticker\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "TRAINING_TIMESTAMP = datetime.now()\n",
    "\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886f393",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please install the 'db-dtypes' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:59\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdb_dtypes\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     date_dtype_name \u001b[38;5;241m=\u001b[39m db_dtypes\u001b[38;5;241m.\u001b[39mDateDtype\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'db_dtypes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient(PROJECT_ID)\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mSELECT Ticker, Date, Open, High, Low, Close, Volume\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mFROM `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTABLE_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(query)\u001b[38;5;241m.\u001b[39mto_dataframe()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/bigquery/job/query.py:2060\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1854\u001b[0m \n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m   2061\u001b[0m     bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[1;32m   2062\u001b[0m     dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[1;32m   2063\u001b[0m     progress_bar_type\u001b[38;5;241m=\u001b[39mprogress_bar_type,\n\u001b[1;32m   2064\u001b[0m     create_bqstorage_client\u001b[38;5;241m=\u001b[39mcreate_bqstorage_client,\n\u001b[1;32m   2065\u001b[0m     geography_as_object\u001b[38;5;241m=\u001b[39mgeography_as_object,\n\u001b[1;32m   2066\u001b[0m     bool_dtype\u001b[38;5;241m=\u001b[39mbool_dtype,\n\u001b[1;32m   2067\u001b[0m     int_dtype\u001b[38;5;241m=\u001b[39mint_dtype,\n\u001b[1;32m   2068\u001b[0m     float_dtype\u001b[38;5;241m=\u001b[39mfloat_dtype,\n\u001b[1;32m   2069\u001b[0m     string_dtype\u001b[38;5;241m=\u001b[39mstring_dtype,\n\u001b[1;32m   2070\u001b[0m     date_dtype\u001b[38;5;241m=\u001b[39mdate_dtype,\n\u001b[1;32m   2071\u001b[0m     datetime_dtype\u001b[38;5;241m=\u001b[39mdatetime_dtype,\n\u001b[1;32m   2072\u001b[0m     time_dtype\u001b[38;5;241m=\u001b[39mtime_dtype,\n\u001b[1;32m   2073\u001b[0m     timestamp_dtype\u001b[38;5;241m=\u001b[39mtimestamp_dtype,\n\u001b[1;32m   2074\u001b[0m     range_date_dtype\u001b[38;5;241m=\u001b[39mrange_date_dtype,\n\u001b[1;32m   2075\u001b[0m     range_datetime_dtype\u001b[38;5;241m=\u001b[39mrange_datetime_dtype,\n\u001b[1;32m   2076\u001b[0m     range_timestamp_dtype\u001b[38;5;241m=\u001b[39mrange_timestamp_dtype,\n\u001b[1;32m   2077\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/bigquery/table.py:2529\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2295\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2296\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \n\u001b[1;32m   2319\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2529\u001b[0m     _pandas_helpers\u001b[38;5;241m.\u001b[39mverify_pandas_imports()\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:1144\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'db-dtypes' package to use this function."
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(PROJECT_ID)\n",
    "query = f\"\"\"\n",
    "SELECT Ticker, Date, Open, High, Low, Close, Volume\n",
    "FROM `{TABLE_ID}`\n",
    "WHERE \n",
    "    Ticker in ('AAPL', 'NVDA', 'MSFT')\n",
    "    AND Date >= DATE_SUB(CURRENT_DATE(), INTERVAL 1 YEAR)\n",
    "\"\"\"\n",
    "\n",
    "df = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c86d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker        Date        Open        High         Low       Close    Volume\n",
      "0   AAPL  2024-04-24  165.757322  168.504360  165.428886  168.225677  48251800\n",
      "1   AAPL  2024-04-25  168.733259  169.808185  167.359740  169.091568  50558300\n",
      "2   AAPL  2024-04-26  169.081625  170.534755  168.384902  168.504349  44838400\n",
      "3   AAPL  2024-04-29  172.555222  175.202725  172.286502  172.684616  68169400\n",
      "4   AAPL  2024-04-30  172.515412  174.167614  169.201060  169.529510  65934800\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750 entries, 0 to 749\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Ticker  750 non-null    object \n",
      " 1   Date    750 non-null    dbdate \n",
      " 2   Open    750 non-null    float64\n",
      " 3   High    750 non-null    float64\n",
      " 4   Low     750 non-null    float64\n",
      " 5   Close   750 non-null    float64\n",
      " 6   Volume  750 non-null    Int64  \n",
      "dtypes: Int64(1), dbdate(1), float64(4), object(1)\n",
      "memory usage: 41.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())\n",
    "tickers = df[\"Ticker\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5901ef",
   "metadata": {},
   "source": [
    "### ARIMA Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5dd7d3",
   "metadata": {},
   "source": [
    "#### Model training and Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5798d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING AAPL\n",
      "AAPL - ARIMA(2, 1, 3) | RMSE: 20.52, MAE: 16.95\n",
      "PROCESSING MSFT\n",
      "MSFT - ARIMA(0, 1, 0) | RMSE: 27.68, MAE: 23.72\n",
      "PROCESSING NVDA\n",
      "NVDA - ARIMA(1, 1, 1) | RMSE: 21.10, MAE: 18.38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>predicted_close</th>\n",
       "      <th>actual_close</th>\n",
       "      <th>type</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>model</th>\n",
       "      <th>training_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>226.579888</td>\n",
       "      <td>232.619995</td>\n",
       "      <td>backtest</td>\n",
       "      <td>20.516729</td>\n",
       "      <td>16.952645</td>\n",
       "      <td>ARIMA(2, 1, 3)</td>\n",
       "      <td>2025-04-24 23:30:22.387106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>227.212975</td>\n",
       "      <td>236.869995</td>\n",
       "      <td>backtest</td>\n",
       "      <td>20.516729</td>\n",
       "      <td>16.952645</td>\n",
       "      <td>ARIMA(2, 1, 3)</td>\n",
       "      <td>2025-04-24 23:30:22.387106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>226.999487</td>\n",
       "      <td>241.529999</td>\n",
       "      <td>backtest</td>\n",
       "      <td>20.516729</td>\n",
       "      <td>16.952645</td>\n",
       "      <td>ARIMA(2, 1, 3)</td>\n",
       "      <td>2025-04-24 23:30:22.387106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>226.783258</td>\n",
       "      <td>244.600006</td>\n",
       "      <td>backtest</td>\n",
       "      <td>20.516729</td>\n",
       "      <td>16.952645</td>\n",
       "      <td>ARIMA(2, 1, 3)</td>\n",
       "      <td>2025-04-24 23:30:22.387106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>227.401567</td>\n",
       "      <td>244.470001</td>\n",
       "      <td>backtest</td>\n",
       "      <td>20.516729</td>\n",
       "      <td>16.952645</td>\n",
       "      <td>ARIMA(2, 1, 3)</td>\n",
       "      <td>2025-04-24 23:30:22.387106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  predicted_close  actual_close      type       rmse  \\\n",
       "0  2025-02-11   AAPL       226.579888    232.619995  backtest  20.516729   \n",
       "1  2025-02-12   AAPL       227.212975    236.869995  backtest  20.516729   \n",
       "2  2025-02-13   AAPL       226.999487    241.529999  backtest  20.516729   \n",
       "3  2025-02-14   AAPL       226.783258    244.600006  backtest  20.516729   \n",
       "4  2025-02-18   AAPL       227.401567    244.470001  backtest  20.516729   \n",
       "\n",
       "         mae           model         training_timestamp  \n",
       "0  16.952645  ARIMA(2, 1, 3) 2025-04-24 23:30:22.387106  \n",
       "1  16.952645  ARIMA(2, 1, 3) 2025-04-24 23:30:22.387106  \n",
       "2  16.952645  ARIMA(2, 1, 3) 2025-04-24 23:30:22.387106  \n",
       "3  16.952645  ARIMA(2, 1, 3) 2025-04-24 23:30:22.387106  \n",
       "4  16.952645  ARIMA(2, 1, 3) 2025-04-24 23:30:22.387106  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "forecast_records = []\n",
    "best_orders_by_ticker = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"PROCESSING {ticker}\")\n",
    "    try:\n",
    "        ticker_df = df[df[\"Ticker\"] == ticker].sort_values(\"Date\")\n",
    "        ticker_df.set_index(\"Date\", inplace=True)\n",
    "        series = ticker_df[\"Close\"]\n",
    "\n",
    "        if len(series) < 20:\n",
    "            print(f\"Not enough data for {ticker}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        train_size = int(len(series) * 0.8)\n",
    "        train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "        best_aic = float(\"inf\")\n",
    "        best_order = None\n",
    "        best_model = None\n",
    "\n",
    "        for p in range(0, 4):\n",
    "            for d in range(0, 2):\n",
    "                for q in range(0, 4):\n",
    "                    try:\n",
    "                        model = ARIMA(train, order=(p, d, q))\n",
    "                        model_fit = model.fit()\n",
    "                        if model_fit.aic < best_aic:\n",
    "                            best_aic = model_fit.aic\n",
    "                            best_order = (p, d, q)\n",
    "                            best_model = model_fit\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        if best_model:\n",
    "            best_orders_by_ticker[ticker] = best_order\n",
    "            forecast = best_model.forecast(len(test))\n",
    "            forecast.index = test.index\n",
    "            rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "            mae = mean_absolute_error(test, forecast)\n",
    "            print(f\"{ticker} - ARIMA{best_order} | RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "            for date in test.index:\n",
    "                forecast_records.append({\n",
    "                    \"date\": date,\n",
    "                    \"ticker\": ticker,\n",
    "                    \"predicted_close\": forecast.loc[date],\n",
    "                    \"actual_close\": test.loc[date],\n",
    "                    \"type\": \"backtest\",\n",
    "                    \"rmse\": rmse,\n",
    "                    \"mae\": mae,\n",
    "                    \"model\": f\"ARIMA{best_order}\",\n",
    "                    \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "backtest_forecast_df = pd.DataFrame(forecast_records)\n",
    "backtest_forecast_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef22ba6",
   "metadata": {},
   "source": [
    "#### 7-Day forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317cbd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTING FUTURE FOR AAPL\n",
      "PREDICTING FUTURE FOR MSFT\n",
      "PREDICTING FUTURE FOR NVDA\n",
      "         date ticker  predicted_close actual_close        type  rmse   mae  \\\n",
      "16 2025-04-26   NVDA       102.846001         None  prediction  None  None   \n",
      "17 2025-04-27   NVDA       102.766716         None  prediction  None  None   \n",
      "18 2025-04-28   NVDA       102.828999         None  prediction  None  None   \n",
      "19 2025-04-29   NVDA       102.780072         None  prediction  None  None   \n",
      "20 2025-04-30   NVDA       102.818507         None  prediction  None  None   \n",
      "\n",
      "             model         training_timestamp  \n",
      "16  ARIMA(1, 1, 1) 2025-04-24 23:30:22.387106  \n",
      "17  ARIMA(1, 1, 1) 2025-04-24 23:30:22.387106  \n",
      "18  ARIMA(1, 1, 1) 2025-04-24 23:30:22.387106  \n",
      "19  ARIMA(1, 1, 1) 2025-04-24 23:30:22.387106  \n",
      "20  ARIMA(1, 1, 1) 2025-04-24 23:30:22.387106  \n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "forecast_records = []\n",
    "for ticker in tickers:\n",
    "    print(f\"PREDICTING FUTURE FOR {ticker}\")\n",
    "    try:\n",
    "        if ticker not in best_orders_by_ticker:\n",
    "            print(f\"No ARIMA order found from backtest for {ticker}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        order = best_orders_by_ticker[ticker]\n",
    "        ticker_df = df[df[\"Ticker\"] == ticker].sort_values(\"Date\")\n",
    "        ticker_df.set_index(\"Date\", inplace=True)\n",
    "        series = ticker_df[\"Close\"]\n",
    "\n",
    "        model = ARIMA(series, order=order)\n",
    "        model_fit = model.fit()\n",
    "        forecast = model_fit.forecast(steps=7)\n",
    "\n",
    "        last_date = series.index[-1]\n",
    "        forecast_dates = pd.date_range(start=last_date + timedelta(days=1), periods=7, freq=\"D\")\n",
    "\n",
    "        for date, pred in zip(forecast_dates, forecast):\n",
    "            forecast_records.append({\n",
    "                \"date\": date,\n",
    "                \"ticker\": ticker,\n",
    "                \"predicted_close\": pred,\n",
    "                \"actual_close\": None,\n",
    "                \"type\": \"prediction\",\n",
    "                \"rmse\": None,\n",
    "                \"mae\": None,\n",
    "                \"model\": f\"ARIMA{order}\",\n",
    "                \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting future for {ticker}: {e}\")\n",
    "\n",
    "\n",
    "prediction_forecast_df = pd.DataFrame(forecast_records)\n",
    "print(prediction_forecast_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc6a5a",
   "metadata": {},
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c2f7b",
   "metadata": {},
   "source": [
    "#### Model training and Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85444353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"Ticker\", \"Date\"])\n",
    "\n",
    "for window in [5, 10, 20]:\n",
    "    df[f\"MA_{window}\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.rolling(window).mean())\n",
    "    df[f\"Volume_MA_{window}\"] = df.groupby(\"Ticker\")[\"Volume\"].transform(lambda x: x.rolling(window).mean())\n",
    "\n",
    "for lag in range(1, 8):\n",
    "    df[f\"lag_{lag}\"] = df.groupby(\"Ticker\")[\"Close\"].shift(lag)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    df[f\"Close_t+{i}\"] = df.groupby(\"Ticker\")[\"Close\"].shift(-i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648a694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost for AAPL\n",
      "Training XGBoost for MSFT\n",
      "Training XGBoost for NVDA\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "forecast_records = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Training XGBoost for {ticker}\")\n",
    "    ticker_df = df[df[\"Ticker\"] == ticker]\n",
    "\n",
    "    feature_cols = ['Open', 'High', 'Low', 'Volume',\n",
    "                    'MA_5', 'MA_10', 'MA_20',\n",
    "                    'Volume_MA_5', 'Volume_MA_10', 'Volume_MA_20'] + \\\n",
    "                   [f\"lag_{i}\" for i in range(1, 8)]\n",
    "    \n",
    "    target_cols = [f\"Close_t+{i}\" for i in range(1, 8)]\n",
    "\n",
    "    X = ticker_df[feature_cols]\n",
    "    y = ticker_df[target_cols]\n",
    "\n",
    "    # Split data for backtesting\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    model = MultiOutputRegressor(XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5))\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "\n",
    "    test_dates = ticker_df[\"Date\"].iloc[train_size:].reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        actuals = y_test.iloc[i].values\n",
    "\n",
    "        for day in range(7):  # Predict each future day (t+1 to t+7)\n",
    "            predicted_close = y_pred[i][day]\n",
    "            \n",
    "            all_predictions.append(predicted_close)\n",
    "            all_actuals.append(actuals[day])\n",
    "\n",
    "            forecast_records.append({\n",
    "                \"date\": test_dates[i] + pd.Timedelta(days=day+1),  # t+1 to t+7\n",
    "                \"ticker\": ticker,\n",
    "                \"predicted_close\": predicted_close,\n",
    "                \"actual_close\": actuals[day],\n",
    "                \"type\": \"backtest\",\n",
    "                \"rmse\": None,\n",
    "                \"mae\": None, \n",
    "                \"model\": \"XGBoost\",\n",
    "                \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "            })\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_actuals = np.array(all_actuals)\n",
    "\n",
    "    valid_mask = ~np.isnan(all_predictions) & ~np.isnan(all_actuals)\n",
    "\n",
    "    total_rmse = np.sqrt(mean_squared_error(all_actuals[valid_mask], all_predictions[valid_mask]))\n",
    "    total_mae = mean_absolute_error(all_actuals[valid_mask], all_predictions[valid_mask])\n",
    "\n",
    "    for record in forecast_records:\n",
    "        if record[\"type\"] == \"backtest\" and record[\"ticker\"] == ticker:\n",
    "            record[\"rmse\"] = total_rmse\n",
    "            record[\"mae\"] = total_mae\n",
    "\n",
    "    X_latest = X.iloc[[-1]]\n",
    "    y_future_pred = model.predict(X_latest)[0]\n",
    "\n",
    "    last_date = ticker_df[\"Date\"].max()\n",
    "    forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=7)\n",
    "\n",
    "    for i, pred in enumerate(y_future_pred):\n",
    "        forecast_records.append({\n",
    "            \"date\": forecast_dates[i],\n",
    "            \"ticker\": ticker,\n",
    "            \"predicted_close\": pred,\n",
    "            \"actual_close\": None,\n",
    "            \"type\": \"prediction\",\n",
    "            \"rmse\": None,\n",
    "            \"mae\": None,\n",
    "            \"model\": \"XGBoost\",\n",
    "            \"training_timestamp\": TRAINING_TIMESTAMP\n",
    "        })\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd46747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     date ticker  predicted_close  actual_close        type  \\\n",
      "1066  2025-04-26 00:00:00   NVDA       113.823341           NaN  prediction   \n",
      "1067  2025-04-27 00:00:00   NVDA       118.419632           NaN  prediction   \n",
      "1068  2025-04-28 00:00:00   NVDA       117.731133           NaN  prediction   \n",
      "1069  2025-04-29 00:00:00   NVDA       116.603783           NaN  prediction   \n",
      "1070  2025-04-30 00:00:00   NVDA       116.843796           NaN  prediction   \n",
      "\n",
      "      rmse  mae    model         training_timestamp  \n",
      "1066   NaN  NaN  XGBoost 2025-04-24 23:30:22.387106  \n",
      "1067   NaN  NaN  XGBoost 2025-04-24 23:30:22.387106  \n",
      "1068   NaN  NaN  XGBoost 2025-04-24 23:30:22.387106  \n",
      "1069   NaN  NaN  XGBoost 2025-04-24 23:30:22.387106  \n",
      "1070   NaN  NaN  XGBoost 2025-04-24 23:30:22.387106  \n"
     ]
    }
   ],
   "source": [
    "xgboost_prediction_forecast_df = pd.DataFrame(forecast_records)\n",
    "print(xgboost_prediction_forecast_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56571fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "DESTINATION_TABLE_ID = \"is3107-project-455413.market_data.stock_forecast\"\n",
    "final_forecast_df = pd.concat([backtest_forecast_df, prediction_forecast_df, xgboost_prediction_forecast_df])\n",
    "\n",
    "final_forecast_df[\"date\"] = pd.to_datetime(final_forecast_df[\"date\"], errors='coerce')\n",
    "final_forecast_df[\"training_timestamp\"] = pd.to_datetime(final_forecast_df[\"training_timestamp\"], errors='coerce')\n",
    "\n",
    "final_forecast_df[\"ticker\"] = final_forecast_df[\"ticker\"].astype(str)\n",
    "final_forecast_df[\"type\"] = final_forecast_df[\"type\"].astype(str)\n",
    "final_forecast_df[\"model\"] = final_forecast_df[\"model\"].astype(str)\n",
    "\n",
    "final_forecast_df[\"predicted_close\"] = pd.to_numeric(final_forecast_df[\"predicted_close\"], errors='coerce')\n",
    "final_forecast_df[\"actual_close\"] = pd.to_numeric(final_forecast_df[\"actual_close\"], errors='coerce')\n",
    "\n",
    "to_gbq(\n",
    "    final_forecast_df,\n",
    "    DESTINATION_TABLE_ID,\n",
    "    project_id=PROJECT_ID,\n",
    "    if_exists='append',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
